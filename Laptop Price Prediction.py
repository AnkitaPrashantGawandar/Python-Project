# -*- coding: utf-8 -*-
"""LAPTOPPRICEPREDICTION1ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Wk_OVktj2h_EmvISRALM0-WLwaAe-xv
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("/content/laptop_price (1).csv",encoding='latin')
df.head()

df.shape

df.info()

df.sample(3)

df.drop(columns=['laptop_ID'],inplace=True)

df.drop(columns=['Product'],inplace=True)

df.head()

df.isnull().sum()

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.shape

df['Price']=round(df['Price_euros']*89.66).astype('int')

df.head()

1339.69*89.66 #Price Conversion Check

df.sample()

#EDA #Before Filtering
df['Company'].value_counts().plot(kind='bar')

#Groupby to get the average amount of each brand
df.groupby('Company')['Price'].mean()

#Filtering for only those companies which has repeat more the 10 times in the dataset to reduce the category in the data and assigning back to df
df=df[df.groupby('Company')['Company'].transform('count')>10]

df['Company'].value_counts().plot(kind='bar')#After Filtering

df.head()

df.reset_index(drop=True,inplace=True)

sns.barplot(x='Company',y='Price',data=df)
plt.show()

df.sample()

df['TypeName'].value_counts()

sns.barplot(x=df['TypeName'],y=df['Price'])
plt.xticks(rotation=90)
plt.show()

df['Inches'].value_counts()

df['Inches'].value_counts().plot(kind='bar')

sns.displot(df['Inches'],kde=True)

"""1.The smooth curve overlays the histogram and represents the estimated probability density function.

2.Peaks in the curve indicate where the data points are concentrated.
"""

sns.barplot(x=df['Inches'],y=df['Price'])
plt.xticks(rotation=90)
plt.show()

sns.scatterplot(x=df['Inches'],y=df['Price'])
plt.xticks(rotation=90)
plt.show()

df['ScreenResolution'].value_counts()

#X_Res
#Y_Res

a='IPS Panel Touchscreen/4K Ultra HD 3840x2160'
type(a)

a.split()

a.split()[-1].split('x')

a.split()[-1].split('x')[0]

a.split()[-1].split('x')[1]

(lambda x:x.split()[-1].split('x')[0])('IPS Panel Touchscreen / 4K Ultra HD 3840x2160')

(lambda x:x.split()[-1].split('x')[1])('IPS Panel Touchscreen / 4K Ultra HD 3840x2160')

df.sample()

df['X_Res']=df['ScreenResolution'].apply(lambda x:x.split()[-1].split('x')[0]).astype('int')

df['Y_Res']=df['ScreenResolution'].apply(lambda x : x.split()[-1].split('x')[1]).astype('int')

df.sample()

df['ScreenResolution'].value_counts()

a='IPS Panel Touchscreen 4K Ultra HD 3840x2160'

(lambda a:1 if "Touchscreen" in a else 0)('IPS Panel Touchscreen / 4K Ultra HD 3840x2160')

(lambda a:1 if "IPS" in a else 0)('IPS PAnel Touchscreen / 4K Ultra HD 3840x2160')

df['Touchscreen']=df['ScreenResolution'].apply((lambda a:1 if "Touchscreen" in a else 0))

df['IPS']=df['ScreenResolution'].apply((lambda a:1 if "IPS" in a else 0))

df.sample()

df.drop(columns=['ScreenResolution'],inplace=True)

df.head()

df.sample()

df['Cpu']

df['Cpu'].value_counts().plot(kind='bar')

#I want to fetch the first 3 words i.e Intel Core i5/i7/i3....
#I just want to fetch the Series of AMD i.e E/A/D....
#Wherever i have something like(Intel celeron Dual Core N3050 1.6GHz/Intel Pentium / Intel Quad)i want to categorize it as intel CPU

a='Intel Core i5 7200U 2.5GHz'

a.split()

a.split()[0:3]

#Intel core i5

" ".join(a.split()[0:3])

(lambda a:" ".join(a.split()[0:3]))('Intel Core i5 7200U 2.5GHz')

df['Cpu']=df['Cpu'].apply(lambda a:" ".join(a.split()[0:3]))

df['Cpu'].value_counts()

def fetch_processor(text):
  if text=='Intel Core i7' or text=='Intel Core i5' or text=='Intel Core i3':
    return text
  elif text.split()[0]=='Intel':
    return 'other Intel Processor'
  else:
    if text[4]=='E':
      return 'AMD E Series Processor'
    elif text[4]=='A':
      return 'AMD A Series Processor'
    elif text[4]=='D':
      return 'AMD D Series Processor'
    elif text[4]=='F':
      return 'AMD F Series Processor'
    else:
      return 'AMD Ryzen Series'

fetch_processor(df['Cpu'][5])

df['Cpu']=df['Cpu'].apply(fetch_processor)

df['Cpu'].value_counts()

df['Cpu'].value_counts().plot(kind='bar')

sns.barplot(x=df['Cpu'],y=df['Price'])
plt.xticks(rotation=90)
plt.show()

df.sample()

df['Ram'].value_counts()

a='4GB'

a.replace("GB","")

df['Ram']=df['Ram'].apply(lambda a:a.replace("GB","")).astype('int')

df['Ram'].value_counts().plot(kind='bar')

sns.barplot(x=df['Ram'],y=df['Price'])
plt.xticks(rotation=90)
plt.show()

df.sample()

#SSd+HDD
#Flash Storage
#SSD+SSd
#Flash Storage+HDD
#SSD+Hybrid
#HDD+HDD
new=df['Memory'].str.split('+',n=1,expand=True)
df['first']=new[0]
df['first']=df['first'].str.strip()
df['second']=new[1]

df['Layer1HDD']=df['first'].apply(lambda x:1 if "HDD" in x else 0)
df['Layer1SSD']=df['first'].apply(lambda x:1 if "SSD" in x else 0)
df['Layer1Hybrid']=df['first'].apply(lambda x:1 if "Hybrid" in x else 0)
df['Layer1Flash_Storage']=df['first'].apply(lambda x:1 if "Flash Storage" in x else 0)
df['first']=df['first'].str.replace(r'\D','',regex=True)

df['second'].fillna("0",inplace=True)

df['second']=df['second'].str.strip()
df['Layer2HDD']=df['second'].apply(lambda x:1 if "HDD" in x else 0)
df['Layer2SSD']=df['second'].apply(lambda x:1 if "SSD" in x else 0)
df['Layer2Hybrid']=df['second'].apply(lambda x:1 if "Hybrid" in x else 0)
df['Layer2Flash_Storage']=df['second'].apply(lambda x:1 if "Flash Storage" in x else 0)

df['second']=df['second'].str.replace(r'\D','',regex=True)

df['first']=df['first'].astype('int')
df['second']=df['second'].astype('int')

df['HDD']=df['first']*df['Layer1HDD']+df['second']*df['Layer2HDD']
df['SSD']=df['first']*df['Layer1SSD']+df['second']*df['Layer2SSD']
df['Hybrid']=df['first']*df['Layer1Hybrid']+df['second']*df['Layer2Hybrid']
df['Flash_Storage']=df['first']*df['Layer1Flash_Storage']+df['second']*df['Layer2Flash_Storage']
df.drop(columns=['first','second','Layer1HDD','Layer1SSD','Layer1Hybrid','Layer1Flash_Storage','Layer2HDD','Layer2SSD','Layer2Hybrid','Layer2Flash_Storage'],inplace=True)

df['Memory'].value_counts()

df.drop(columns=['Memory'],inplace=True)

df.sample()

df['Gpu'].value_counts()

a='Intel HD Graphics 620'

a.split()[0:2]

" ".join(a.split()[0:2])

lambda a: " ".join(a.split()[0:2])

df['Gpu']=df['Gpu'].apply(lambda a:" ".join(a.split()[0:2]))

df['Gpu'].value_counts()

sns.barplot(x=df['Gpu'],y=df['Price'])
plt.xticks(rotation=90)
plt.show()

df.sample()

df['OpSys'].value_counts()

#Wherever we have windows 10 or windows 10 S >>> Windows 10
#Window 7>>>Windows 7
#If we have Mac OS X or macOS >>>Mac os
#If No OS >>>No OS
#Chrome /Linux/Android

def os(text):
  if text=='Windows 10' or text=='Windows 10 S':
    return 'Windows 10'
  elif text=='Windows 7':
    return 'Windows 7'
  elif text=="Mac OS X" or text=='macOS':
    return 'Mac OS'
  elif text=="No OS":
    return 'No OS'
  else:
    return 'Chrome/Linux/Android'

os('Linux')

df['OpSys']=df['OpSys'].apply(os)

df['OpSys'].value_counts()

df['OpSys'].value_counts().plot(kind='bar')

df.head()

sns.barplot(x=df['OpSys'],y=df['Price'])
plt.xticks(rotation=90)
plt.show()

df[df['OpSys']=='Windows 10']['Price'].describe()

sns.displot(data=df,x='OpSys',y='Price')

df.shape

df['Weight']=df['Weight'].apply(lambda a:a.replace("kg","")).astype('float')

df['Weight'].describe()

sns.displot(x=df['Weight'],kde=True)
plt.show()

sns.scatterplot(x=df['Weight'],y=df['Price'])

df.sample()

df['Y_Res'].value_counts()

df.corr(numeric_only=True)['Price']

#ppi Pixels per inches
df['ppi']=round(((df['X_Res']**2)+(df['Y_Res']**2))**0.5/df['Inches'])

df.sample()

df.corr(numeric_only=True)['Price']

df.shape

df.drop(columns=['Inches','X_Res','Y_Res'],inplace=True)

df.shape

sns.scatterplot(x=df['ppi'],y=df['Price'])

df['Touchscreen'].value_counts()

df['Touchscreen'].value_counts().plot(kind='bar')

df['IPS'].value_counts()

sns.barplot(x=df['Touchscreen'],y=df['Price'])

sns.barplot(x=df['IPS'],y=df['Price'])

df.head()

df['ppi'].describe()

df.to_csv("/content/Cleaned_data.csv")#Exploring the cleaned data in csv format

#ML>LR>DTR>KNN>RFR>Lasso and Ridge>Adaboost>GDB
#One Hot Encoding

#Training And Deploying
#Feature Scaling > Standardization > Normalization >>>When and Where
#Imbalance Data>> Undersampling>Oversampling

# One Hot Encoder >>> Human Lang >>> Machine Lang 0,1
df.sample()

df.info()

df['Company'].unique()

#Machine Learning
#1.Define I/p n O/P columns

x=df.drop(columns=['Price']) #I/P
x

y=df['Price'] #o/p
y

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.15,random_state=42)

y_train

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error

from sklearn.linear_model import LinearRegression,Lasso,Ridge
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor

df.sample()

#Linear Regression
categorical_features=['Company','TypeName','Cpu','Gpu','OpSys']
step1=ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(sparse_output=False,handle_unknown='ignore'),categorical_features)],remainder='passthrough')

step2=LinearRegression()
pipe=Pipeline([('step',step1),('step2',step2)])
pipe.fit(x_train,y_train)
pipe.predict(x_test)
y_pred=pipe.predict(x_test)
print("R2 Score",r2_score(y_test,y_pred))
print("MAE",mean_absolute_error(y_test,y_pred))
print("MSE",mean_squared_error(y_test,y_pred))

x_test



categorical_features = ['Company','TypeName','Cpu','Gpu','OpSys']

step1 =ColumnTransformer(transformers = [
    ('col_tnf',OneHotEncoder(sparse_output= False , handle_unknown='ignore'),categorical_features)
],remainder = 'passthrough')

step2 = Lasso()

pipe = Pipeline([('step1',step1) , ('step2',step2)])

pipe.fit(x_train , y_train)

pipe.predict(x_test)

y_pred = pipe.predict(x_test)


print("R2 Score",r2_score(y_test , y_pred))
print("MAE",mean_absolute_error(y_test , y_pred))
print("MSE",mean_squared_error(y_test , y_pred))

#Lasso Regression
categorical_features=['Company','TypeName','Cpu','Gpu','OpSys']
step1=ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(sparse_output=False,handle_unknown='ignore'),categorical_features)],remainder='passthrough')
step2=Ridge()
pipe=Pipeline([('step1',step1),('step2',step2)])
pipe.fit(x_train , y_train)
pipe.predict(x_test)
y_pred=pipe.predict(x_test)
print("R2 Score",r2_score(y_test,y_pred))
print("MAE",mean_absolute_error(y_test , y_pred))
print("MSE",mean_squared_error(y_test , y_pred))

#KNN Regressor
categorical_features=['Company','TypeName','Cpu','Gpu','OpSys']
step1=ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(sparse_output=False,handle_unknown='ignore'),categorical_features)],
                        remainder='passthrough')
step2=KNeighborsRegressor()
pipe=Pipeline([('step1',step1),('step2',step2)])
pipe.fit(x_train , y_train)
pipe.predict(x_test)
y_pred=pipe.predict(x_test)
print("R2 Score",r2_score(y_test , y_pred))
print("MAE",mean_absolute_error(y_test , y_pred))
print("MSE",mean_squared_error(y_test ,y_pred))

#Decision Tree Regressor
categorical_features = ['Company','TypeName','Cpu','Gpu','OpSys']

step1 =ColumnTransformer(transformers = [
    ('col_tnf',OneHotEncoder(sparse_output= False , handle_unknown='ignore'),categorical_features)
],remainder = 'passthrough')

step2 = DecisionTreeRegressor(max_depth = 4 )

pipe = Pipeline([('step1',step1) , ('step2',step2)])

pipe.fit(x_train , y_train)

pipe.predict(x_test)

y_pred = pipe.predict(x_test)


print("R2 Score",r2_score(y_test , y_pred))
print("MAE",mean_absolute_error(y_test , y_pred))
print("MSE",mean_squared_error(y_test , y_pred))

#Adaboost Regressor
categorical_features=['Company','TypeName','Cpu','Gpu','OpSys']
step1=ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(sparse_output=False,handle_unknown='ignore'),categorical_features)],remainder='passthrough')
step2=AdaBoostRegressor(n_estimators=80)
pipe=Pipeline([('step1',step1),('step2',step2)])
pipe.fit(x_train , y_train)
pipe.predict(x_test)
y_pred=pipe.predict(x_test)
print("R2 Score",r2_score(y_test , y_pred))
print("MAE",mean_absolute_error(y_test ,y_pred))
print("MSE",mean_squared_error(y_test , y_pred))

#GradientBoosting Regressor
categorical_features=['Company','TypeName','Cpu','Gpu','OpSys']
step1=ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(sparse_output=False, handle_unknown='ignore'),categorical_features)],
                        remainder='passthrough')
step2=GradientBoostingRegressor(n_estimators=500)
pipe=Pipeline([('step1',step1),('step2',step2)])
pipe.fit(x_train , y_train)
y_pred=pipe.predict(x_test)
print("R2 Score",r2_score(y_test , y_pred))
print("MAE",mean_absolute_error(y_test , y_pred))
print("MSE",mean_squared_error(y_test , y_pred))

#Random Forest Regressor
categorical_features=['Company','TypeName','Cpu','Gpu','OpSys']
step1=ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(sparse_output=False,handle_unknown='ignore'),categorical_features)],remainder='passthrough')
step2=RandomForestRegressor()
pipe=Pipeline([('step1',step1),('step2',step2)])
pipe.fit(x_train , y_train)
pipe.predict(x_test)
y_pred=pipe.predict(x_test)
print("R2 Score",r2_score(y_test , y_pred))
print("MAE",mean_absolute_error(y_test , y_pred))
print("MSE",mean_squared_error(y_test , y_pred))

import pickle
pickle.dump(df,open('dataframe.pkl','wb'))
pickle.dump(pipe,open('pipe.pkl','wb'))

df.sample()

#Compressed the DF n Algo wrt pickle

df['Company'].unique()

df['TypeName'].unique()

df['OpSys'].unique()

df.describe()

df['Weight']

screen_resolution='2560x1600'

int(screen_resolution.split('x')[0])

int(screen_resolution.split('x')[1])

df.to_csv("Cleaned.csv")